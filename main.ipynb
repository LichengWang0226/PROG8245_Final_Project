{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ask Anything Monday - Weekly Thread\n",
      "Module Six Milestone IT-140\n",
      "I decided to start learning Python, but have a question.\n",
      "Type-hinting Overloaded Operators\n",
      "What's the difference between the 'as' keyword and thewalrus operator (:=)?\n",
      "Python Institute 2 Exam\n",
      "i can't understand how the solution of the tower of Hanoi works (recursion)\n",
      "This code is running but it's not functioning properly, can anyone help?\n",
      "is it possible to implement a class like this?\n",
      "Lambda Polars Binary Error\n"
     ]
    }
   ],
   "source": [
    "import praw\n",
    "\n",
    "# 初始化 Reddit 實例\n",
    "reddit = praw.Reddit(\n",
    "    client_id=\"Adgs1BqKFWPstMUG3G4MZA\",        # 你從 Reddit 應用程序獲取的 client_id\n",
    "    client_secret=\"G5ekLZQxg43T87UTrmwxZcacCGkGeQ\",# 你從 Reddit 應用程序獲取的 client_secret\n",
    "    user_agent=\"Chatbot\",      # 一個描述你的應用程序用途的字符串\n",
    ")\n",
    "\n",
    "# 測試：打印某個 subreddit 的前 10 條熱門帖子\n",
    "subreddit = reddit.subreddit(\"learnpython\")\n",
    "for submission in subreddit.hot(limit=10):\n",
    "    print(submission.title)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Data Collection (25 marks)\n",
    "### 1.1 Collecting Data Using Reddit API (PRAW)\n",
    "We will use the PRAW library to collect question-answer pairs from Reddit. This data will be used to train our chatbot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import json\n",
    "\n",
    "\n",
    "# 選擇一個 subreddit\n",
    "subreddit = reddit.subreddit(\"AskReddit\")\n",
    "\n",
    "# 使用集合來追踪已收集的問題\n",
    "collected_questions = set()\n",
    "qa_pairs = []\n",
    "\n",
    "# 收集問答對\n",
    "for submission in subreddit.hot(limit=2000):  # 調整 limit 來收集更多數據\n",
    "    if not submission.stickied:  # 過濾置頂貼文\n",
    "        question = submission.title.strip().lower()  # 去除多餘空格並轉換為小寫以進行去重\n",
    "        if question not in collected_questions and len(question) > 10:  # 過濾掉過短的問題\n",
    "            submission.comments.replace_more(limit=0)\n",
    "            for comment in submission.comments:\n",
    "                if comment.body and not comment.stickied and len(comment.body) > 20:  # 過濾短回答\n",
    "                    qa_pairs.append((question, comment.body))\n",
    "                    collected_questions.add(question)  # 添加到已收集的問題集合中\n",
    "                    break  # 只收集每個問題的一個回答\n",
    "\n",
    "# 將數據保存為 JSON 格式\n",
    "with open('reddit_qa_data.json', 'w') as f:\n",
    "    json.dump(qa_pairs, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Annotating the Dataset with Sentiment Labels\n",
    "We will use a pretrained model from Hugging Face to automatically annotate the data with sentiment labels (e.g., positive, neutral, negative). These labels will later be used to influence the chatbot's responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a95632e73aeb497589e93d970615b044",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f007ab38dcb9497584bc99d94879f30e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0727f382866047bea0b5c474c576ecea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a0f02379cc545a59387d9638eb213dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load a pretrained sentiment analysis model\n",
    "classifier = pipeline('sentiment-analysis')\n",
    "\n",
    "# Annotate each answer with a sentiment label\n",
    "annotated_data = []\n",
    "for question, answer in qa_pairs:\n",
    "    sentiment = classifier(answer)[0]\n",
    "    annotated_data.append({'question': question, 'answer': answer, 'label': sentiment['label']})\n",
    "\n",
    "# Save the annotated data\n",
    "with open('annotated_reddit_qa_data.json', 'w') as f:\n",
    "    json.dump(annotated_data, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preprocessing (20 marks)\n",
    "### 2.1 Basic Text Preprocessing\n",
    "We will preprocess the text by tokenizing, removing stop words, lemmatizing, and converting to lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/lichengwang/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/lichengwang/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/lichengwang/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stop words\n",
    "    filtered_tokens = [word for word in tokens if word.isalnum() and word not in stop_words]\n",
    "    # Lemmatize\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in filtered_tokens]\n",
    "    return ' '.join(lemmatized_tokens)\n",
    "\n",
    "# Preprocess all texts in the dataset\n",
    "for item in annotated_data:\n",
    "    item['preprocessed_question'] = preprocess_text(item['question'])\n",
    "    item['preprocessed_answer'] = preprocess_text(item['answer'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Handling Special Text Challenges\n",
    "We will handle special characters, emojis, hashtags, etc., to ensure the data is clean and suitable for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji\n",
    "\n",
    "def preprocess_special_tokens(text):\n",
    "    # Remove emojis\n",
    "    text = emoji.replace_emoji(text, replace='')\n",
    "    # Remove hashtags\n",
    "    text = text.replace('#', '')\n",
    "    return text\n",
    "\n",
    "# Apply special token preprocessing\n",
    "for item in annotated_data:\n",
    "    item['preprocessed_question'] = preprocess_special_tokens(item['preprocessed_question'])\n",
    "    item['preprocessed_answer'] = preprocess_special_tokens(item['preprocessed_answer'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Feature Extraction (20 marks)\n",
    "We will use a pretrained BERT model to extract semantic embeddings from the text. These embeddings will be used as input to the Seq2Seq model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acf85ba8fcde4b0abfa49d633723acc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1153e6b4f5b744858a48759265588bb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08c693ff709c4c43b4f4e1e6e67b8bc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4c397f37a974eda81caa1b3c0399682",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b76d1100c354fc5a54a446832494573",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# Load the pretrained BERT model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def get_bert_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', max_length=512, truncation=True, padding=True)\n",
    "    with torch.no_grad():  # No need to compute gradients\n",
    "        outputs = bert_model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
    "\n",
    "# Generate BERT embeddings for the questions\n",
    "bert_embeddings = np.array([get_bert_embeddings(item['preprocessed_question']) for item in annotated_data])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Model Selection and Training (15 marks)\n",
    "### 4.1 Building the Seq2Seq Model\n",
    "We will build and train a Seq2Seq model using the BERT embeddings as input to the encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Get the dimension of BERT embeddings\n",
    "embedding_dim = bert_embeddings.shape[2]\n",
    "\n",
    "# Define the Seq2Seq model\n",
    "encoder_inputs = Input(shape=(embedding_dim,))  # BERT embeddings as input\n",
    "encoder_lstm = LSTM(units=512, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
    "\n",
    "decoder_inputs = Input(shape=(None,))  # Decoder input remains as sequence data\n",
    "decoder_embedding = Dense(embedding_dim, activation='relu')(decoder_inputs)  # Embedding layer\n",
    "decoder_lstm = LSTM(units=512, return_sequences=True, return_state=False)\n",
    "decoder_outputs = decoder_lstm(decoder_embedding, initial_state=[state_h, state_c])\n",
    "\n",
    "decoder_dense = Dense(vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Prepare decoder input data\n",
    "decoder_input_data = np.array([get_bert_embeddings(item['preprocessed_answer']) for item in annotated_data])\n",
    "\n",
    "# Train the model\n",
    "model.fit([bert_embeddings, decoder_input_data], target_sequences, epochs=10, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Model Evaluation\n",
    "We will evaluate the model on a test set and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(bert_embeddings, target_sequences, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model and make predictions\n",
    "model.fit([X_train, y_train], y_train, epochs=10, batch_size=64)\n",
    "y_pred = model.predict([X_test, y_test])\n",
    "\n",
    "# Evaluate model performance\n",
    "accuracy = accuracy_score(y_test, y_pred.argmax(axis=-1))\n",
    "print(f\"Model Accuracy: {accuracy}\")\n",
    "print(classification_report(y_test, y_pred.argmax(axis=-1)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Deployment and Interface Development (10 marks)\n",
    "### 5.1 Developing a Simple Chatbot Interface\n",
    "We will use Tkinter to create a simple interface that allows users to input questions and get responses generated by the model in real-time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "\n",
    "def generate_response():\n",
    "    user_input = entry.get()\n",
    "    preprocessed_input = preprocess_text(user_input)\n",
    "    input_bert_embedding = get_bert_embeddings(preprocessed_input)\n",
    "    \n",
    "    prediction = model.predict([input_bert_embedding, decoder_input_data])\n",
    "    predicted_seq = prediction.argmax(axis=-1)\n",
    "    response = tokenizer.sequences_to_texts(predicted_seq)[0]\n",
    "    \n",
    "    result_label.config(text=response)\n",
    "\n",
    "# Simple Tkinter UI\n",
    "root = tk.Tk()\n",
    "root.title(\"Seq2Seq Chatbot\")\n",
    "\n",
    "entry = tk.Entry(root, width=50)\n",
    "entry.pack()\n",
    "\n",
    "button = tk.Button(root, text=\"Generate Response\", command=generate_response)\n",
    "button.pack()\n",
    "\n",
    "result_label = tk.Label(root, text=\"\")\n",
    "result_label.pack()\n",
    "\n",
    "root.mainloop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
